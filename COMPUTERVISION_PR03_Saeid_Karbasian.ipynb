{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple Model**"
      ],
      "metadata": {
        "id": "nOFeXrTHK20Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio diffusers transformers accelerate safetensors\n",
        "\n",
        "import gradio as gr\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionXLPipeline\n",
        "import torch\n",
        "from PIL import Image\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "import gc\n",
        "import random\n",
        "\n",
        "# Check if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"üîµ Running in Google Colab\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"üîµ Running in local environment\")\n",
        "\n",
        "# Global configuration\n",
        "CONFIG = {\n",
        "    \"max_generations\": 500,\n",
        "    \"generation_count\": 0,\n",
        "    \"history_file\": \"generation_history.json\",\n",
        "    \"models\": {\n",
        "        \"SD 1.5 Fast\": {\n",
        "            \"model_id\": \"runwayml/stable-diffusion-v1-5\",\n",
        "            \"type\": \"sd15\",\n",
        "            \"description\": \"Fast and efficient for quick generation\"\n",
        "        },\n",
        "        \"SD 1.5 Quality\": {\n",
        "            \"model_id\": \"stabilityai/stable-diffusion-2-1\",\n",
        "            \"type\": \"sd15\",\n",
        "            \"description\": \"Higher quality SD 1.5 model\"\n",
        "        },\n",
        "        \"SDXL Base\": {\n",
        "            \"model_id\": \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "            \"type\": \"sdxl\",\n",
        "            \"description\": \"Highest quality SDXL model\"\n",
        "        },\n",
        "        \"OpenJourney\": {\n",
        "            \"model_id\": \"prompthero/openjourney\",\n",
        "            \"type\": \"sd15\",\n",
        "            \"description\": \"Artistic style model\"\n",
        "        }\n",
        "    },\n",
        "    \"image_sizes\": {\n",
        "        \"SD 1.5\": {\n",
        "            \"512x512 (Square)\": (512, 512),\n",
        "            \"768x512 (Landscape)\": (768, 512),\n",
        "            \"512x768 (Portrait)\": (512, 768),\n",
        "            \"640x640 (Large Square)\": (640, 640)\n",
        "        },\n",
        "        \"SDXL\": {\n",
        "            \"1024x1024 (Square)\": (1024, 1024),\n",
        "            \"1152x896 (Landscape)\": (1152, 896),\n",
        "            \"896x1152 (Portrait)\": (896, 1152),\n",
        "            \"1344x768 (Wide)\": (1344, 768),\n",
        "            \"768x1344 (Tall)\": (768, 1344)\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "class SmartImageGenerator:\n",
        "    def __init__(self):\n",
        "        self.pipeline = None\n",
        "        self.current_model = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.load_history()\n",
        "\n",
        "    def load_history(self):\n",
        "        \"\"\"Load generation history from file\"\"\"\n",
        "        try:\n",
        "            if os.path.exists(CONFIG[\"history_file\"]):\n",
        "                with open(CONFIG[\"history_file\"], 'r', encoding='utf-8') as f:\n",
        "                    self.history = json.load(f)\n",
        "                    CONFIG[\"generation_count\"] = len(self.history)\n",
        "            else:\n",
        "                self.history = []\n",
        "                CONFIG[\"generation_count\"] = 0\n",
        "        except:\n",
        "            self.history = []\n",
        "            CONFIG[\"generation_count\"] = 0\n",
        "\n",
        "    def save_history(self):\n",
        "        \"\"\"Save generation history to file\"\"\"\n",
        "        try:\n",
        "            with open(CONFIG[\"history_file\"], 'w', encoding='utf-8') as f:\n",
        "                json.dump(self.history, f, ensure_ascii=False, indent=2)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving history: {e}\")\n",
        "\n",
        "    def load_model(self, model_name, progress=gr.Progress()):\n",
        "        \"\"\"Load selected model with progress tracking\"\"\"\n",
        "        if self.current_model == model_name and self.pipeline is not None:\n",
        "            return f\"‚úÖ Model {model_name} is already loaded\"\n",
        "\n",
        "        try:\n",
        "            progress(0.1, desc=\"Clearing memory...\")\n",
        "            # Clear previous model\n",
        "            if self.pipeline is not None:\n",
        "                del self.pipeline\n",
        "                gc.collect()\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "            model_info = CONFIG[\"models\"][model_name]\n",
        "            model_id = model_info[\"model_id\"]\n",
        "            model_type = model_info[\"type\"]\n",
        "\n",
        "            progress(0.3, desc=f\"Loading {model_name}...\")\n",
        "\n",
        "            # Load appropriate pipeline based on model type\n",
        "            if model_type == \"sdxl\":\n",
        "                self.pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
        "                    model_id,\n",
        "                    torch_dtype=torch.float16,\n",
        "                    use_safetensors=True,\n",
        "                    variant=\"fp16\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "            else:\n",
        "                self.pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "                    model_id,\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    safety_checker=None,\n",
        "                    requires_safety_checker=False\n",
        "                )\n",
        "\n",
        "            progress(0.7, desc=\"Moving to device...\")\n",
        "            self.pipeline = self.pipeline.to(self.device)\n",
        "\n",
        "            # Memory optimization\n",
        "            if hasattr(self.pipeline, 'enable_attention_slicing'):\n",
        "                self.pipeline.enable_attention_slicing()\n",
        "            if hasattr(self.pipeline, 'enable_model_cpu_offload') and torch.cuda.is_available():\n",
        "                self.pipeline.enable_model_cpu_offload()\n",
        "\n",
        "            progress(1.0, desc=\"Ready!\")\n",
        "            self.current_model = model_name\n",
        "\n",
        "            return f\"‚úÖ {model_name} loaded successfully!\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error loading model: {str(e)}\"\n",
        "\n",
        "    def get_available_sizes(self, model_name):\n",
        "        \"\"\"Get available image sizes for selected model\"\"\"\n",
        "        try:\n",
        "            model_type = CONFIG[\"models\"][model_name][\"type\"]\n",
        "            if model_type == \"sdxl\":\n",
        "                return list(CONFIG[\"image_sizes\"][\"SDXL\"].keys())\n",
        "            else:\n",
        "                return list(CONFIG[\"image_sizes\"][\"SD 1.5\"].keys())\n",
        "        except:\n",
        "            return list(CONFIG[\"image_sizes\"][\"SD 1.5\"].keys())\n",
        "\n",
        "    def generate_image(self, prompt, negative_prompt, model_name, size_name,\n",
        "                      cfg_scale, steps, seed, progress=gr.Progress()):\n",
        "        \"\"\"Generate image with all parameters\"\"\"\n",
        "\n",
        "        # Check generation limit\n",
        "        if CONFIG[\"generation_count\"] >= CONFIG[\"max_generations\"]:\n",
        "            return None, f\"‚ùå Generation limit reached ({CONFIG['max_generations']} images)\"\n",
        "\n",
        "        # Check if model is loaded\n",
        "        if self.pipeline is None or self.current_model != model_name:\n",
        "            return None, \"‚ùå Please load the model first\"\n",
        "\n",
        "        # Validate inputs\n",
        "        if not prompt.strip():\n",
        "            return None, \"‚ùå Please enter a prompt\"\n",
        "\n",
        "        try:\n",
        "            progress(0.1, desc=\"Preparing generation...\")\n",
        "\n",
        "            # Get image size\n",
        "            model_type = CONFIG[\"models\"][model_name][\"type\"]\n",
        "            if model_type == \"sdxl\" and size_name in CONFIG[\"image_sizes\"][\"SDXL\"]:\n",
        "                width, height = CONFIG[\"image_sizes\"][\"SDXL\"][size_name]\n",
        "            elif size_name in CONFIG[\"image_sizes\"][\"SD 1.5\"]:\n",
        "                width, height = CONFIG[\"image_sizes\"][\"SD 1.5\"][size_name]\n",
        "            else:\n",
        "                # Fallback to default size\n",
        "                width, height = (512, 512)\n",
        "\n",
        "            # Handle seed\n",
        "            if seed == -1:\n",
        "                seed = random.randint(0, 2**32-1)\n",
        "\n",
        "            generator = torch.Generator(device=self.device).manual_seed(int(seed))\n",
        "\n",
        "            progress(0.3, desc=\"Generating image...\")\n",
        "\n",
        "            # Generate image\n",
        "            with torch.no_grad():\n",
        "                result = self.pipeline(\n",
        "                    prompt=prompt,\n",
        "                    negative_prompt=negative_prompt if negative_prompt.strip() else None,\n",
        "                    width=width,\n",
        "                    height=height,\n",
        "                    num_inference_steps=int(steps),\n",
        "                    guidance_scale=float(cfg_scale),\n",
        "                    generator=generator\n",
        "                )\n",
        "                image = result.images[0]\n",
        "\n",
        "            progress(0.9, desc=\"Saving...\")\n",
        "\n",
        "            # Save image and update history\n",
        "            filename = f\"generated_{CONFIG['generation_count']+1}_{seed}.png\"\n",
        "            image.save(filename)\n",
        "\n",
        "            # Add to history\n",
        "            generation_info = {\n",
        "                \"id\": CONFIG[\"generation_count\"] + 1,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"prompt\": prompt,\n",
        "                \"negative_prompt\": negative_prompt,\n",
        "                \"model\": model_name,\n",
        "                \"size\": size_name,\n",
        "                \"width\": width,\n",
        "                \"height\": height,\n",
        "                \"cfg_scale\": cfg_scale,\n",
        "                \"steps\": steps,\n",
        "                \"seed\": seed,\n",
        "                \"filename\": filename\n",
        "            }\n",
        "\n",
        "            self.history.append(generation_info)\n",
        "            CONFIG[\"generation_count\"] += 1\n",
        "            self.save_history()\n",
        "\n",
        "            progress(1.0, desc=\"Complete!\")\n",
        "\n",
        "            status = f\"‚úÖ Image {CONFIG['generation_count']} generated successfully!\\n\"\n",
        "            status += f\"üå± Seed: {seed}\\n\"\n",
        "            status += f\"üìä Remaining: {CONFIG['max_generations'] - CONFIG['generation_count']} images\"\n",
        "\n",
        "            return image, status\n",
        "\n",
        "        except Exception as e:\n",
        "            return None, f\"‚ùå Generation error: {str(e)}\"\n",
        "\n",
        "    def get_generation_stats(self):\n",
        "        \"\"\"Get current generation statistics\"\"\"\n",
        "        return {\n",
        "            \"total\": CONFIG[\"generation_count\"],\n",
        "            \"limit\": CONFIG[\"max_generations\"],\n",
        "            \"remaining\": CONFIG[\"max_generations\"] - CONFIG[\"generation_count\"]\n",
        "        }\n",
        "\n",
        "def create_interface():\n",
        "    \"\"\"Create the main Gradio interface\"\"\"\n",
        "    generator = SmartImageGenerator()\n",
        "\n",
        "    # Custom CSS for better styling\n",
        "    css = \"\"\"\n",
        "    .gradio-container {\n",
        "        font-family: 'Segoe UI', 'Roboto', sans-serif !important;\n",
        "        max-width: 1400px !important;\n",
        "    }\n",
        "    .title-header {\n",
        "        text-align: center;\n",
        "        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\n",
        "        -webkit-background-clip: text;\n",
        "        -webkit-text-fill-color: transparent;\n",
        "        font-size: 2.5rem;\n",
        "        font-weight: bold;\n",
        "        margin: 20px 0;\n",
        "    }\n",
        "    .stats-card {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        padding: 20px;\n",
        "        border-radius: 15px;\n",
        "        text-align: center;\n",
        "        margin: 10px 0;\n",
        "    }\n",
        "    .model-info {\n",
        "        background: #f8f9fa;\n",
        "        padding: 15px;\n",
        "        border-radius: 10px;\n",
        "        border-left: 4px solid #667eea;\n",
        "        margin: 10px 0;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    with gr.Blocks(title=\"üé® Smart Text-to-Image Generator\", css=css) as interface:\n",
        "\n",
        "        # Header\n",
        "        gr.HTML(\"\"\"\n",
        "            <div class=\"title-header\">\n",
        "                üé® Smart Text-to-Image Generator\n",
        "            </div>\n",
        "            <div style=\"text-align: center; color: #666; font-size: 1.2em; margin-bottom: 30px;\">\n",
        "                Transform your imagination into stunning visuals with AI\n",
        "            </div>\n",
        "        \"\"\")\n",
        "\n",
        "        # Statistics display\n",
        "        with gr.Row():\n",
        "            stats_display = gr.HTML()\n",
        "\n",
        "        with gr.Row():\n",
        "            # Left column - Controls\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"## ‚öôÔ∏è Model & Settings\")\n",
        "\n",
        "                # Model selection\n",
        "                model_selector = gr.Dropdown(\n",
        "                    choices=list(CONFIG[\"models\"].keys()),\n",
        "                    value=\"SD 1.5 Fast\",\n",
        "                    label=\"ü§ñ Select Model\",\n",
        "                    info=\"Choose the AI model for generation\"\n",
        "                )\n",
        "\n",
        "                model_info = gr.HTML()\n",
        "\n",
        "                load_model_btn = gr.Button(\n",
        "                    \"üì• Load Model\",\n",
        "                    variant=\"secondary\",\n",
        "                    size=\"lg\"\n",
        "                )\n",
        "\n",
        "                model_status = gr.Textbox(\n",
        "                    label=\"Model Status\",\n",
        "                    value=\"‚ùå No model loaded\",\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "                gr.Markdown(\"## üé® Generation Settings\")\n",
        "\n",
        "                # Prompt inputs\n",
        "                prompt = gr.Textbox(\n",
        "                    label=\"‚úçÔ∏è Prompt\",\n",
        "                    placeholder=\"A beautiful landscape with mountains and lake, highly detailed, 8k\",\n",
        "                    lines=4\n",
        "                )\n",
        "\n",
        "                negative_prompt = gr.Textbox(\n",
        "                    label=\"üö´ Negative Prompt\",\n",
        "                    placeholder=\"blurry, low quality, distorted\",\n",
        "                    lines=2,\n",
        "                    value=\"blurry, low quality, worst quality\"\n",
        "                )\n",
        "\n",
        "                # Size selection (dynamic based on model)\n",
        "                size_selector = gr.Dropdown(\n",
        "                    label=\"üìê Image Size\",\n",
        "                    choices=generator.get_available_sizes(\"SD 1.5 Fast\"),\n",
        "                    value=\"512x512 (Square)\"\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    # CFG Scale\n",
        "                    cfg_scale = gr.Slider(\n",
        "                        minimum=1.0,\n",
        "                        maximum=20.0,\n",
        "                        value=7.5,\n",
        "                        step=0.5,\n",
        "                        label=\"‚öñÔ∏è CFG Scale\",\n",
        "                        info=\"Controls how closely the AI follows your prompt\"\n",
        "                    )\n",
        "\n",
        "                    # Steps\n",
        "                    steps = gr.Slider(\n",
        "                        minimum=10,\n",
        "                        maximum=100,\n",
        "                        value=30,\n",
        "                        step=5,\n",
        "                        label=\"üîÑ Steps\",\n",
        "                        info=\"More steps = better quality but slower\"\n",
        "                    )\n",
        "\n",
        "                # Seed\n",
        "                seed = gr.Number(\n",
        "                    label=\"üå± Seed\",\n",
        "                    value=-1,\n",
        "                    precision=0,\n",
        "                    info=\"-1 for random seed\"\n",
        "                )\n",
        "\n",
        "                # Generate button\n",
        "                generate_btn = gr.Button(\n",
        "                    \"üöÄ Generate Image\",\n",
        "                    variant=\"primary\",\n",
        "                    size=\"lg\"\n",
        "                )\n",
        "\n",
        "                # Quick actions\n",
        "                with gr.Row():\n",
        "                    random_seed_btn = gr.Button(\"üé≤ Random Seed\", size=\"sm\")\n",
        "                    clear_btn = gr.Button(\"üóëÔ∏è Clear\", size=\"sm\")\n",
        "\n",
        "                # Example prompts\n",
        "                gr.Examples(\n",
        "                    examples=[\n",
        "                        \"A majestic dragon soaring over a mystical forest, fantasy art, highly detailed\",\n",
        "                        \"Portrait of a wise old wizard, realistic, professional photography, 8k\",\n",
        "                        \"Cyberpunk cityscape at night, neon lights, futuristic, digital art\",\n",
        "                        \"Peaceful zen garden with cherry blossoms, serene atmosphere, beautiful lighting\",\n",
        "                        \"Astronaut exploring an alien planet, sci-fi, cinematic, epic\"\n",
        "                    ],\n",
        "                    inputs=prompt,\n",
        "                    label=\"üí° Example Prompts\"\n",
        "                )\n",
        "\n",
        "            # Right column - Results\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"## üñºÔ∏è Generated Image\")\n",
        "\n",
        "                # Image output\n",
        "                output_image = gr.Image(\n",
        "                    label=\"Result\",\n",
        "                    type=\"pil\",\n",
        "                    height=500\n",
        "                )\n",
        "\n",
        "                # Generation status\n",
        "                generation_status = gr.Textbox(\n",
        "                    label=\"üìä Generation Status\",\n",
        "                    interactive=False,\n",
        "                    lines=3\n",
        "                )\n",
        "\n",
        "                # Image actions\n",
        "                with gr.Row():\n",
        "                    download_btn = gr.Button(\"üíæ Download\", variant=\"secondary\")\n",
        "                    share_btn = gr.Button(\"üîó Share\", variant=\"secondary\")\n",
        "\n",
        "        # History tab\n",
        "        with gr.Tab(\"üìö Generation History\"):\n",
        "            history_display = gr.Dataframe(\n",
        "                headers=[\"ID\", \"Time\", \"Prompt\", \"Model\", \"Size\", \"Seed\"],\n",
        "                label=\"Recent Generations\",\n",
        "                interactive=False\n",
        "            )\n",
        "            refresh_history_btn = gr.Button(\"üîÑ Refresh History\")\n",
        "\n",
        "        # Help tab\n",
        "        with gr.Tab(\"üìñ User Guide\"):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ## üéØ How to Use\n",
        "\n",
        "            ### Step-by-Step Guide:\n",
        "            1. **Select Model**: Choose between SD 1.5 (fast) or SDXL (high quality)\n",
        "            2. **Load Model**: Click \"Load Model\" and wait for confirmation\n",
        "            3. **Write Prompt**: Describe your desired image in English\n",
        "            4. **Adjust Settings**: Configure CFG scale, steps, and image size\n",
        "            5. **Generate**: Click \"Generate Image\" and wait for the result\n",
        "\n",
        "            ### Model Comparison:\n",
        "            - **SD 1.5 Fast**: Quick generation, good for testing ideas\n",
        "            - **SD 1.5 Quality**: Better quality, slightly slower\n",
        "            - **SDXL Base**: Highest quality, requires more memory\n",
        "            - **OpenJourney**: Artistic style, unique aesthetic\n",
        "\n",
        "            ### Parameter Guide:\n",
        "            - **CFG Scale**: 1-5 (creative), 7-10 (balanced), 15+ (strict adherence)\n",
        "            - **Steps**: 20-30 (fast), 30-50 (quality), 50+ (maximum quality)\n",
        "            - **Seed**: Use same seed to reproduce results\n",
        "\n",
        "            ### Pro Tips:\n",
        "            - Use detailed, descriptive prompts in English\n",
        "            - Include quality keywords: \"highly detailed\", \"8k\", \"professional\"\n",
        "            - Use negative prompts to avoid unwanted elements\n",
        "            - Experiment with different CFG scales for varied results\n",
        "\n",
        "            ### Limitations:\n",
        "            - Maximum 500 images per session\n",
        "            - SDXL requires significant GPU memory\n",
        "            - Generation time varies by settings and hardware\n",
        "            \"\"\")\n",
        "\n",
        "        # Event handlers\n",
        "        def update_stats():\n",
        "            stats = generator.get_generation_stats()\n",
        "            return f\"\"\"\n",
        "            <div class=\"stats-card\">\n",
        "                <h3>üìä Generation Statistics</h3>\n",
        "                <p><strong>{stats['total']}</strong> / {stats['limit']} images generated</p>\n",
        "                <p><strong>{stats['remaining']}</strong> generations remaining</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        def update_model_info(model_name):\n",
        "            info = CONFIG[\"models\"][model_name]\n",
        "            return f\"\"\"\n",
        "            <div class=\"model-info\">\n",
        "                <h4>ü§ñ {model_name}</h4>\n",
        "                <p>{info['description']}</p>\n",
        "                <p><strong>Type:</strong> {info['type'].upper()}</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        def update_size_options(model_name):\n",
        "            available_sizes = generator.get_available_sizes(model_name)\n",
        "            return gr.Dropdown(\n",
        "                choices=available_sizes,\n",
        "                value=available_sizes[0] if available_sizes else \"512x512 (Square)\"\n",
        "            )\n",
        "\n",
        "        def refresh_history():\n",
        "            if not generator.history:\n",
        "                return []\n",
        "\n",
        "            # Get last 50 generations\n",
        "            recent = generator.history[-50:]\n",
        "            history_data = []\n",
        "            for item in recent:\n",
        "                history_data.append([\n",
        "                    item.get(\"id\", \"\"),\n",
        "                    item.get(\"timestamp\", \"\")[:19],\n",
        "                    item.get(\"prompt\", \"\")[:50] + \"...\" if len(item.get(\"prompt\", \"\")) > 50 else item.get(\"prompt\", \"\"),\n",
        "                    item.get(\"model\", \"\"),\n",
        "                    item.get(\"size\", \"\"),\n",
        "                    item.get(\"seed\", \"\")\n",
        "                ])\n",
        "            return history_data\n",
        "\n",
        "        def generate_random_seed():\n",
        "            return random.randint(0, 2**32-1)\n",
        "\n",
        "        def clear_inputs():\n",
        "            return \"\", \"\", -1\n",
        "\n",
        "        # Connect events\n",
        "        model_selector.change(\n",
        "            fn=update_model_info,\n",
        "            inputs=[model_selector],\n",
        "            outputs=[model_info]\n",
        "        )\n",
        "\n",
        "        model_selector.change(\n",
        "            fn=update_size_options,\n",
        "            inputs=[model_selector],\n",
        "            outputs=[size_selector]\n",
        "        )\n",
        "\n",
        "        load_model_btn.click(\n",
        "            fn=generator.load_model,\n",
        "            inputs=[model_selector],\n",
        "            outputs=[model_status]\n",
        "        )\n",
        "\n",
        "        generate_btn.click(\n",
        "            fn=generator.generate_image,\n",
        "            inputs=[prompt, negative_prompt, model_selector, size_selector,\n",
        "                   cfg_scale, steps, seed],\n",
        "            outputs=[output_image, generation_status]\n",
        "        ).then(\n",
        "            fn=update_stats,\n",
        "            outputs=[stats_display]\n",
        "        )\n",
        "\n",
        "        random_seed_btn.click(\n",
        "            fn=generate_random_seed,\n",
        "            outputs=[seed]\n",
        "        )\n",
        "\n",
        "        clear_btn.click(\n",
        "            fn=clear_inputs,\n",
        "            outputs=[prompt, negative_prompt, seed]\n",
        "        )\n",
        "\n",
        "        refresh_history_btn.click(\n",
        "            fn=refresh_history,\n",
        "            outputs=[history_display]\n",
        "        )\n",
        "\n",
        "        # Initialize interface\n",
        "        interface.load(\n",
        "            fn=update_stats,\n",
        "            outputs=[stats_display]\n",
        "        )\n",
        "\n",
        "        interface.load(\n",
        "            fn=update_model_info,\n",
        "            inputs=[gr.State(\"SD 1.5 Fast\")],\n",
        "            outputs=[model_info]\n",
        "        )\n",
        "\n",
        "        interface.load(\n",
        "            fn=refresh_history,\n",
        "            outputs=[history_display]\n",
        "        )\n",
        "\n",
        "    return interface\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main application entry point\"\"\"\n",
        "    global IN_COLAB\n",
        "\n",
        "    print(\"üé® Smart Text-to-Image Generator\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # System info\n",
        "    print(f\"üì± Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "    print(f\"üî¢ Generation Limit: {CONFIG['max_generations']}\")\n",
        "    print(f\"üìä Current Count: {CONFIG['generation_count']}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Create and launch interface\n",
        "    try:\n",
        "        interface = create_interface()\n",
        "\n",
        "        if IN_COLAB:\n",
        "            interface.launch(\n",
        "                share=True,\n",
        "                show_error=True,\n",
        "                quiet=False\n",
        "            )\n",
        "        else:\n",
        "            interface.launch(\n",
        "                share=True,\n",
        "                server_name=\"0.0.0.0\",\n",
        "                server_port=7860,\n",
        "                show_error=True\n",
        "            )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Launch error: {e}\")\n",
        "        print(\"üîÑ Trying simple launch method...\")\n",
        "        interface = create_interface()\n",
        "        interface.launch(share=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "DLOat091k5Uq",
        "outputId": "ee3ed213-dfc7-48d0-dc36-0f0829fd9ae4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîµ Running in Google Colab\n",
            "üé® Smart Text-to-Image Generator\n",
            "==================================================\n",
            "üì± Device: CUDA\n",
            "üéÆ GPU: Tesla T4\n",
            "üíæ GPU Memory: 14.7 GB\n",
            "üî¢ Generation Limit: 500\n",
            "üìä Current Count: 0\n",
            "==================================================\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c625f8b29c8fee4feb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c625f8b29c8fee4feb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advanced Model**"
      ],
      "metadata": {
        "id": "MVQ7O4dlPKLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio diffusers transformers accelerate safetensors plotly pandas\n",
        "\n",
        "import gradio as gr\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionXLPipeline, DPMSolverMultistepScheduler\n",
        "import torch\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "import gc\n",
        "import random\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Check if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"üöÄ Running in Google Colab - Enhanced Version\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"üöÄ Running in local environment - Enhanced Version\")\n",
        "\n",
        "# Enhanced Global Configuration\n",
        "CONFIG = {\n",
        "    \"max_generations\": 1000,\n",
        "    \"generation_count\": 0,\n",
        "    \"history_file\": \"generation_history_enhanced.json\",\n",
        "    \"presets_file\": \"generation_presets.json\",\n",
        "    \"favorites_file\": \"favorite_generations.json\",\n",
        "    \"models\": {\n",
        "        \"SD 1.5 Fast\": {\n",
        "            \"model_id\": \"runwayml/stable-diffusion-v1-5\",\n",
        "            \"type\": \"sd15\",\n",
        "            \"description\": \"‚ö° Fast and efficient for quick generation\",\n",
        "            \"optimal_settings\": {\"steps\": 25, \"cfg\": 7.5}\n",
        "        },\n",
        "        \"SD 1.5 Quality\": {\n",
        "            \"model_id\": \"stabilityai/stable-diffusion-2-1\",\n",
        "            \"type\": \"sd15\",\n",
        "            \"description\": \"üé® Higher quality SD 1.5 model\",\n",
        "            \"optimal_settings\": {\"steps\": 40, \"cfg\": 8.0}\n",
        "        },\n",
        "        \"SDXL Base\": {\n",
        "            \"model_id\": \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "            \"type\": \"sdxl\",\n",
        "            \"description\": \"üíé Highest quality SDXL model\",\n",
        "            \"optimal_settings\": {\"steps\": 50, \"cfg\": 7.5}\n",
        "        },\n",
        "        \"OpenJourney\": {\n",
        "            \"model_id\": \"prompthero/openjourney\",\n",
        "            \"type\": \"sd15\",\n",
        "            \"description\": \"üñºÔ∏è Artistic style model\",\n",
        "            \"optimal_settings\": {\"steps\": 35, \"cfg\": 7.0}\n",
        "        },\n",
        "        \"DreamShaper\": {\n",
        "            \"model_id\": \"Lykon/DreamShaper\",\n",
        "            \"type\": \"sd15\",\n",
        "            \"description\": \"‚ú® Fantasy and dream-like images\",\n",
        "            \"optimal_settings\": {\"steps\": 30, \"cfg\": 6.5}\n",
        "        },\n",
        "        \"Realistic Vision\": {\n",
        "            \"model_id\": \"SG161222/Realistic_Vision_V5.1_noVAE\",\n",
        "            \"type\": \"sd15\",\n",
        "            \"description\": \"üì∏ Photorealistic portraits and scenes\",\n",
        "            \"optimal_settings\": {\"steps\": 35, \"cfg\": 7.0}\n",
        "        }\n",
        "    },\n",
        "    \"image_sizes\": {\n",
        "        \"SD 1.5\": {\n",
        "            \"512x512 (Square)\": (512, 512),\n",
        "            \"768x512 (Landscape)\": (768, 512),\n",
        "            \"512x768 (Portrait)\": (512, 768),\n",
        "            \"640x640 (Large Square)\": (640, 640),\n",
        "            \"896x512 (Wide)\": (896, 512),\n",
        "            \"512x896 (Tall)\": (512, 896),\n",
        "            \"704x512 (Photo)\": (704, 512),\n",
        "            \"512x704 (Photo Portrait)\": (512, 704)\n",
        "        },\n",
        "        \"SDXL\": {\n",
        "            \"1024x1024 (Square)\": (1024, 1024),\n",
        "            \"1152x896 (Landscape)\": (1152, 896),\n",
        "            \"896x1152 (Portrait)\": (896, 1152),\n",
        "            \"1344x768 (Wide)\": (1344, 768),\n",
        "            \"768x1344 (Tall)\": (768, 1344),\n",
        "            \"1536x640 (Ultra Wide)\": (1536, 640),\n",
        "            \"1216x832 (Photo)\": (1216, 832),\n",
        "            \"832x1216 (Photo Portrait)\": (832, 1216)\n",
        "        }\n",
        "    },\n",
        "    \"schedulers\": [\"PNDM\", \"DDIM\", \"DPM Solver++\", \"Euler\", \"Euler a\", \"DDPM\"],\n",
        "    \"style_presets\": {\n",
        "        \"Photorealistic\": {\n",
        "            \"positive\": \"photorealistic, 8k uhd, dslr, high quality, film grain, Fujifilm XT3\",\n",
        "            \"negative\": \"cartoon, painting, illustration, (worst quality, low quality:1.4)\"\n",
        "        },\n",
        "        \"Digital Art\": {\n",
        "            \"positive\": \"digital painting, artstation, concept art, smooth, sharp focus, illustration\",\n",
        "            \"negative\": \"photo, realistic, realism, ugly\"\n",
        "        },\n",
        "        \"Anime\": {\n",
        "            \"positive\": \"anime style, manga, pixiv, kawaii, colorful\",\n",
        "            \"negative\": \"realistic, photo, western comic\"\n",
        "        },\n",
        "        \"Fantasy\": {\n",
        "            \"positive\": \"fantasy art, magical, ethereal, mystical, enchanted\",\n",
        "            \"negative\": \"modern, technology, mundane\"\n",
        "        },\n",
        "        \"Cyberpunk\": {\n",
        "            \"positive\": \"cyberpunk, neon, futuristic, tech noir, blade runner style\",\n",
        "            \"negative\": \"medieval, ancient, natural\"\n",
        "        },\n",
        "        \"Oil Painting\": {\n",
        "            \"positive\": \"oil painting, traditional art, brushstrokes, canvas texture\",\n",
        "            \"negative\": \"digital, photography, 3d render\"\n",
        "        },\n",
        "        \"Watercolor\": {\n",
        "            \"positive\": \"watercolor painting, soft edges, artistic, traditional media\",\n",
        "            \"negative\": \"digital art, photography, hard edges\"\n",
        "        },\n",
        "        \"3D Render\": {\n",
        "            \"positive\": \"3d render, octane render, unreal engine, volumetric lighting\",\n",
        "            \"negative\": \"2d, painting, drawing, sketch\"\n",
        "        }\n",
        "    },\n",
        "    \"prompt_templates\": {\n",
        "        \"Character Portrait\": \"{subject}, portrait, {style}, detailed face, beautiful lighting, high quality\",\n",
        "        \"Landscape\": \"{location}, landscape, {time_of_day}, {weather}, {style}, scenic, beautiful\",\n",
        "        \"Action Scene\": \"{character} {action}, dynamic pose, {environment}, {style}, motion blur\",\n",
        "        \"Still Life\": \"{objects}, still life, {lighting}, {style}, detailed, artistic composition\",\n",
        "        \"Architecture\": \"{building_type}, {architectural_style}, {time_of_day}, {style}, detailed\"\n",
        "    }\n",
        "}\n",
        "\n",
        "class EnhancedImageGenerator:\n",
        "    def __init__(self):\n",
        "        self.pipeline = None\n",
        "        self.current_model = None\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.scheduler_backup = None\n",
        "        self.load_history()\n",
        "        self.load_presets()\n",
        "        self.load_favorites()\n",
        "        self.generation_times = []\n",
        "        self.model_usage = defaultdict(int)\n",
        "\n",
        "    def load_history(self):\n",
        "        \"\"\"Load generation history from file\"\"\"\n",
        "        try:\n",
        "            if os.path.exists(CONFIG[\"history_file\"]):\n",
        "                with open(CONFIG[\"history_file\"], 'r', encoding='utf-8') as f:\n",
        "                    self.history = json.load(f)\n",
        "                    CONFIG[\"generation_count\"] = len(self.history)\n",
        "            else:\n",
        "                self.history = []\n",
        "                CONFIG[\"generation_count\"] = 0\n",
        "        except:\n",
        "            self.history = []\n",
        "            CONFIG[\"generation_count\"] = 0\n",
        "\n",
        "    def load_presets(self):\n",
        "        \"\"\"Load user presets\"\"\"\n",
        "        try:\n",
        "            if os.path.exists(CONFIG[\"presets_file\"]):\n",
        "                with open(CONFIG[\"presets_file\"], 'r', encoding='utf-8') as f:\n",
        "                    self.presets = json.load(f)\n",
        "            else:\n",
        "                self.presets = {}\n",
        "        except:\n",
        "            self.presets = {}\n",
        "\n",
        "    def load_favorites(self):\n",
        "        \"\"\"Load favorite generations\"\"\"\n",
        "        try:\n",
        "            if os.path.exists(CONFIG[\"favorites_file\"]):\n",
        "                with open(CONFIG[\"favorites_file\"], 'r', encoding='utf-8') as f:\n",
        "                    self.favorites = json.load(f)\n",
        "            else:\n",
        "                self.favorites = []\n",
        "        except:\n",
        "            self.favorites = []\n",
        "\n",
        "    def save_history(self):\n",
        "        \"\"\"Save generation history to file\"\"\"\n",
        "        try:\n",
        "            with open(CONFIG[\"history_file\"], 'w', encoding='utf-8') as f:\n",
        "                json.dump(self.history, f, ensure_ascii=False, indent=2)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving history: {e}\")\n",
        "\n",
        "    def save_presets(self):\n",
        "        \"\"\"Save user presets\"\"\"\n",
        "        try:\n",
        "            with open(CONFIG[\"presets_file\"], 'w', encoding='utf-8') as f:\n",
        "                json.dump(self.presets, f, ensure_ascii=False, indent=2)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving presets: {e}\")\n",
        "\n",
        "    def save_favorites(self):\n",
        "        \"\"\"Save favorites\"\"\"\n",
        "        try:\n",
        "            with open(CONFIG[\"favorites_file\"], 'w', encoding='utf-8') as f:\n",
        "                json.dump(self.favorites, f, ensure_ascii=False, indent=2)\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving favorites: {e}\")\n",
        "\n",
        "    def load_model(self, model_name, scheduler_name=\"DPM Solver++\", progress=gr.Progress()):\n",
        "        \"\"\"Load selected model with scheduler\"\"\"\n",
        "        if self.current_model == model_name and self.pipeline is not None:\n",
        "            # Just update scheduler if model is already loaded\n",
        "            self.set_scheduler(scheduler_name)\n",
        "            return f\"‚úÖ Model {model_name} already loaded. Scheduler updated to {scheduler_name}\"\n",
        "\n",
        "        try:\n",
        "            progress(0.1, desc=\"üßπ Clearing memory...\")\n",
        "            # Clear previous model\n",
        "            if self.pipeline is not None:\n",
        "                del self.pipeline\n",
        "                gc.collect()\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "            model_info = CONFIG[\"models\"][model_name]\n",
        "            model_id = model_info[\"model_id\"]\n",
        "            model_type = model_info[\"type\"]\n",
        "\n",
        "            progress(0.3, desc=f\"üì• Loading {model_name}...\")\n",
        "\n",
        "            # Load appropriate pipeline based on model type\n",
        "            if model_type == \"sdxl\":\n",
        "                self.pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
        "                    model_id,\n",
        "                    torch_dtype=torch.float16,\n",
        "                    use_safetensors=True,\n",
        "                    variant=\"fp16\" if torch.cuda.is_available() else None\n",
        "                )\n",
        "            else:\n",
        "                self.pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "                    model_id,\n",
        "                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "                    safety_checker=None,\n",
        "                    requires_safety_checker=False\n",
        "                )\n",
        "\n",
        "            progress(0.7, desc=\"üöÄ Optimizing...\")\n",
        "            self.pipeline = self.pipeline.to(self.device)\n",
        "\n",
        "            # Memory optimization\n",
        "            if hasattr(self.pipeline, 'enable_attention_slicing'):\n",
        "                self.pipeline.enable_attention_slicing()\n",
        "            if hasattr(self.pipeline, 'enable_model_cpu_offload') and torch.cuda.is_available():\n",
        "                self.pipeline.enable_model_cpu_offload()\n",
        "\n",
        "            # Enable xFormers if available\n",
        "            try:\n",
        "                self.pipeline.enable_xformers_memory_efficient_attention()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Set scheduler\n",
        "            self.set_scheduler(scheduler_name)\n",
        "\n",
        "            progress(1.0, desc=\"‚ú® Ready!\")\n",
        "            self.current_model = model_name\n",
        "            self.model_usage[model_name] += 1\n",
        "\n",
        "            return f\"‚úÖ {model_name} loaded successfully with {scheduler_name} scheduler!\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error loading model: {str(e)}\"\n",
        "\n",
        "    def set_scheduler(self, scheduler_name):\n",
        "        \"\"\"Set the scheduler for the pipeline\"\"\"\n",
        "        if self.pipeline is None:\n",
        "            return\n",
        "\n",
        "        scheduler_config = self.pipeline.scheduler.config\n",
        "\n",
        "        if scheduler_name == \"DPM Solver++\":\n",
        "            self.pipeline.scheduler = DPMSolverMultistepScheduler.from_config(scheduler_config)\n",
        "        # Add other schedulers as needed\n",
        "\n",
        "    def get_available_sizes(self, model_name):\n",
        "        \"\"\"Get available image sizes for selected model\"\"\"\n",
        "        try:\n",
        "            model_type = CONFIG[\"models\"][model_name][\"type\"]\n",
        "            if model_type == \"sdxl\":\n",
        "                return list(CONFIG[\"image_sizes\"][\"SDXL\"].keys())\n",
        "            else:\n",
        "                return list(CONFIG[\"image_sizes\"][\"SD 1.5\"].keys())\n",
        "        except:\n",
        "            return list(CONFIG[\"image_sizes\"][\"SD 1.5\"].keys())\n",
        "\n",
        "    def apply_style_preset(self, preset_name, prompt, negative_prompt):\n",
        "        \"\"\"Apply style preset to prompts\"\"\"\n",
        "        if preset_name == \"None\":\n",
        "            return prompt, negative_prompt\n",
        "\n",
        "        preset = CONFIG[\"style_presets\"].get(preset_name, {})\n",
        "        if preset:\n",
        "            new_prompt = f\"{prompt}, {preset['positive']}\"\n",
        "            new_negative = f\"{negative_prompt}, {preset['negative']}\" if negative_prompt else preset['negative']\n",
        "            return new_prompt, new_negative\n",
        "        return prompt, negative_prompt\n",
        "\n",
        "    def post_process_image(self, image, brightness, contrast, saturation, sharpness):\n",
        "        \"\"\"Apply post-processing to generated image\"\"\"\n",
        "        # Brightness\n",
        "        if brightness != 1.0:\n",
        "            enhancer = ImageEnhance.Brightness(image)\n",
        "            image = enhancer.enhance(brightness)\n",
        "\n",
        "        # Contrast\n",
        "        if contrast != 1.0:\n",
        "            enhancer = ImageEnhance.Contrast(image)\n",
        "            image = enhancer.enhance(contrast)\n",
        "\n",
        "        # Saturation\n",
        "        if saturation != 1.0:\n",
        "            enhancer = ImageEnhance.Color(image)\n",
        "            image = enhancer.enhance(saturation)\n",
        "\n",
        "        # Sharpness\n",
        "        if sharpness != 1.0:\n",
        "            enhancer = ImageEnhance.Sharpness(image)\n",
        "            image = enhancer.enhance(sharpness)\n",
        "\n",
        "        return image\n",
        "\n",
        "    def generate_batch(self, prompt, negative_prompt, model_name, size_name,\n",
        "                      cfg_scale, steps, seed, batch_size, style_preset,\n",
        "                      brightness, contrast, saturation, sharpness,\n",
        "                      progress=gr.Progress()):\n",
        "        \"\"\"Generate multiple images in batch\"\"\"\n",
        "\n",
        "        # Check generation limit\n",
        "        if CONFIG[\"generation_count\"] + batch_size > CONFIG[\"max_generations\"]:\n",
        "            remaining = CONFIG[\"max_generations\"] - CONFIG[\"generation_count\"]\n",
        "            return [], f\"‚ùå Generation limit exceeded. You can generate {remaining} more images.\"\n",
        "\n",
        "        # Check if model is loaded\n",
        "        if self.pipeline is None or self.current_model != model_name:\n",
        "            return [], \"‚ùå Please load the model first\"\n",
        "\n",
        "        # Validate inputs\n",
        "        if not prompt.strip():\n",
        "            return [], \"‚ùå Please enter a prompt\"\n",
        "\n",
        "        generated_images = []\n",
        "        generation_info_list = []\n",
        "\n",
        "        try:\n",
        "            # Apply style preset\n",
        "            styled_prompt, styled_negative = self.apply_style_preset(\n",
        "                style_preset, prompt, negative_prompt\n",
        "            )\n",
        "\n",
        "            # Get image size\n",
        "            model_type = CONFIG[\"models\"][model_name][\"type\"]\n",
        "            if model_type == \"sdxl\" and size_name in CONFIG[\"image_sizes\"][\"SDXL\"]:\n",
        "                width, height = CONFIG[\"image_sizes\"][\"SDXL\"][size_name]\n",
        "            elif size_name in CONFIG[\"image_sizes\"][\"SD 1.5\"]:\n",
        "                width, height = CONFIG[\"image_sizes\"][\"SD 1.5\"][size_name]\n",
        "            else:\n",
        "                width, height = (512, 512)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                progress((i + 0.3) / batch_size, desc=f\"Generating image {i+1}/{batch_size}...\")\n",
        "\n",
        "                # Handle seed\n",
        "                current_seed = seed if seed != -1 else random.randint(0, 2**32-1)\n",
        "                if seed == -1 or i > 0:\n",
        "                    current_seed = random.randint(0, 2**32-1)\n",
        "\n",
        "                generator = torch.Generator(device=self.device).manual_seed(int(current_seed))\n",
        "\n",
        "                # Record start time\n",
        "                start_time = datetime.now()\n",
        "\n",
        "                # Generate image\n",
        "                with torch.no_grad():\n",
        "                    result = self.pipeline(\n",
        "                        prompt=styled_prompt,\n",
        "                        negative_prompt=styled_negative if styled_negative.strip() else None,\n",
        "                        width=width,\n",
        "                        height=height,\n",
        "                        num_inference_steps=int(steps),\n",
        "                        guidance_scale=float(cfg_scale),\n",
        "                        generator=generator\n",
        "                    )\n",
        "                    image = result.images[0]\n",
        "\n",
        "                # Post-process image\n",
        "                image = self.post_process_image(\n",
        "                    image, brightness, contrast, saturation, sharpness\n",
        "                )\n",
        "\n",
        "                # Record generation time\n",
        "                generation_time = (datetime.now() - start_time).total_seconds()\n",
        "                self.generation_times.append(generation_time)\n",
        "\n",
        "                # Save image\n",
        "                filename = f\"enhanced_gen_{CONFIG['generation_count']+i+1}_{current_seed}.png\"\n",
        "                image.save(filename)\n",
        "\n",
        "                # Create generation info\n",
        "                generation_info = {\n",
        "                    \"id\": CONFIG[\"generation_count\"] + i + 1,\n",
        "                    \"timestamp\": datetime.now().isoformat(),\n",
        "                    \"prompt\": prompt,\n",
        "                    \"styled_prompt\": styled_prompt,\n",
        "                    \"negative_prompt\": negative_prompt,\n",
        "                    \"styled_negative_prompt\": styled_negative,\n",
        "                    \"model\": model_name,\n",
        "                    \"size\": size_name,\n",
        "                    \"width\": width,\n",
        "                    \"height\": height,\n",
        "                    \"cfg_scale\": cfg_scale,\n",
        "                    \"steps\": steps,\n",
        "                    \"seed\": current_seed,\n",
        "                    \"filename\": filename,\n",
        "                    \"style_preset\": style_preset,\n",
        "                    \"generation_time\": generation_time,\n",
        "                    \"post_processing\": {\n",
        "                        \"brightness\": brightness,\n",
        "                        \"contrast\": contrast,\n",
        "                        \"saturation\": saturation,\n",
        "                        \"sharpness\": sharpness\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                self.history.append(generation_info)\n",
        "                generation_info_list.append(generation_info)\n",
        "                generated_images.append(image)\n",
        "\n",
        "            CONFIG[\"generation_count\"] += batch_size\n",
        "            self.save_history()\n",
        "\n",
        "            progress(1.0, desc=\"‚ú® Complete!\")\n",
        "\n",
        "            # Create status message\n",
        "            status = f\"‚úÖ Generated {batch_size} images successfully!\\n\"\n",
        "            status += f\"‚è±Ô∏è Average time: {np.mean(self.generation_times[-batch_size:]):.2f}s\\n\"\n",
        "            status += f\"üìä Total: {CONFIG['generation_count']}/{CONFIG['max_generations']}\"\n",
        "\n",
        "            return generated_images, status\n",
        "\n",
        "        except Exception as e:\n",
        "            return [], f\"‚ùå Generation error: {str(e)}\"\n",
        "\n",
        "    def save_preset(self, name, prompt, negative_prompt, cfg_scale, steps, style_preset):\n",
        "        \"\"\"Save current settings as preset\"\"\"\n",
        "        if not name:\n",
        "            return \"‚ùå Please enter a preset name\"\n",
        "\n",
        "        self.presets[name] = {\n",
        "            \"prompt\": prompt,\n",
        "            \"negative_prompt\": negative_prompt,\n",
        "            \"cfg_scale\": cfg_scale,\n",
        "            \"steps\": steps,\n",
        "            \"style_preset\": style_preset\n",
        "        }\n",
        "        self.save_presets()\n",
        "        return f\"‚úÖ Preset '{name}' saved successfully!\"\n",
        "\n",
        "    def load_preset(self, name):\n",
        "        \"\"\"Load a saved preset\"\"\"\n",
        "        if name not in self.presets:\n",
        "            return None, None, 7.5, 30, \"None\"\n",
        "\n",
        "        preset = self.presets[name]\n",
        "        return (\n",
        "            preset.get(\"prompt\", \"\"),\n",
        "            preset.get(\"negative_prompt\", \"\"),\n",
        "            preset.get(\"cfg_scale\", 7.5),\n",
        "            preset.get(\"steps\", 30),\n",
        "            preset.get(\"style_preset\", \"None\")\n",
        "        )\n",
        "\n",
        "    def add_to_favorites(self, generation_id):\n",
        "        \"\"\"Add generation to favorites\"\"\"\n",
        "        for item in self.history:\n",
        "            if item[\"id\"] == generation_id:\n",
        "                if generation_id not in [f[\"id\"] for f in self.favorites]:\n",
        "                    self.favorites.append(item)\n",
        "                    self.save_favorites()\n",
        "                    return \"‚≠ê Added to favorites!\"\n",
        "                else:\n",
        "                    return \"‚ÑπÔ∏è Already in favorites\"\n",
        "        return \"‚ùå Generation not found\"\n",
        "\n",
        "    def get_generation_stats(self):\n",
        "        \"\"\"Get current generation statistics\"\"\"\n",
        "        return {\n",
        "            \"total\": CONFIG[\"generation_count\"],\n",
        "            \"limit\": CONFIG[\"max_generations\"],\n",
        "            \"remaining\": CONFIG[\"max_generations\"] - CONFIG[\"generation_count\"]\n",
        "        }\n",
        "\n",
        "    def get_statistics(self):\n",
        "        \"\"\"Get detailed statistics\"\"\"\n",
        "        if not self.history:\n",
        "            return None, None, None\n",
        "\n",
        "        # Model usage chart\n",
        "        model_counts = defaultdict(int)\n",
        "        style_counts = defaultdict(int)\n",
        "        daily_counts = defaultdict(int)\n",
        "\n",
        "        for item in self.history:\n",
        "            model_counts[item[\"model\"]] += 1\n",
        "            style_counts[item.get(\"style_preset\", \"None\")] += 1\n",
        "            date = item[\"timestamp\"][:10]\n",
        "            daily_counts[date] += 1\n",
        "\n",
        "        # Create charts\n",
        "        fig_models = go.Figure(data=[\n",
        "            go.Bar(x=list(model_counts.keys()), y=list(model_counts.values()),\n",
        "                   marker_color='rgba(102, 126, 234, 0.8)',\n",
        "                   text=list(model_counts.values()),\n",
        "                   textposition='auto')\n",
        "        ])\n",
        "        fig_models.update_layout(\n",
        "            title=\"Model Usage Distribution\",\n",
        "            xaxis_title=\"Model\",\n",
        "            yaxis_title=\"Number of Generations\",\n",
        "            showlegend=False,\n",
        "            template=\"plotly_dark\",\n",
        "            height=400\n",
        "        )\n",
        "\n",
        "        # Generation timeline\n",
        "        dates = sorted(daily_counts.keys())\n",
        "        values = [daily_counts[d] for d in dates]\n",
        "\n",
        "        fig_timeline = go.Figure(data=[\n",
        "            go.Scatter(x=dates, y=values, mode='lines+markers',\n",
        "                      line=dict(color='rgba(78, 205, 196, 1)', width=3),\n",
        "                      marker=dict(size=10, color='rgba(255, 107, 107, 0.8)'),\n",
        "                      fill='tozeroy',\n",
        "                      fillcolor='rgba(78, 205, 196, 0.2)')\n",
        "        ])\n",
        "        fig_timeline.update_layout(\n",
        "            title=\"Generation Timeline\",\n",
        "            xaxis_title=\"Date\",\n",
        "            yaxis_title=\"Generations\",\n",
        "            showlegend=False,\n",
        "            template=\"plotly_dark\",\n",
        "            height=400\n",
        "        )\n",
        "\n",
        "        # Style preferences pie chart\n",
        "        fig_styles = go.Figure(data=[\n",
        "            go.Pie(labels=list(style_counts.keys()), values=list(style_counts.values()),\n",
        "                   hole=.4,\n",
        "                   marker=dict(colors=px.colors.qualitative.Set3))\n",
        "        ])\n",
        "        fig_styles.update_layout(\n",
        "            title=\"Style Preferences\",\n",
        "            template=\"plotly_dark\",\n",
        "            height=400\n",
        "        )\n",
        "\n",
        "        return fig_models, fig_timeline, fig_styles\n",
        "\n",
        "    def export_history(self, format=\"json\"):\n",
        "        \"\"\"Export generation history\"\"\"\n",
        "        if format == \"json\":\n",
        "            return json.dumps(self.history, indent=2)\n",
        "        elif format == \"csv\":\n",
        "            if not self.history:\n",
        "                return \"No data to export\"\n",
        "\n",
        "            df = pd.DataFrame(self.history)\n",
        "            return df.to_csv(index=False)\n",
        "\n",
        "def create_enhanced_interface():\n",
        "    \"\"\"Create the enhanced Gradio interface\"\"\"\n",
        "    generator = EnhancedImageGenerator()\n",
        "\n",
        "    # Custom CSS for modern UI\n",
        "    css = \"\"\"\n",
        "    .gradio-container {\n",
        "        font-family: 'Inter', 'Segoe UI', 'Roboto', sans-serif !important;\n",
        "        max-width: 1600px !important;\n",
        "        background: linear-gradient(135deg, #1e1e2e 0%, #2d2d44 100%);\n",
        "    }\n",
        "    .title-header {\n",
        "        text-align: center;\n",
        "        background: linear-gradient(90deg, #ff6b6b 0%, #4ecdc4 50%, #45b7d1 100%);\n",
        "        -webkit-background-clip: text;\n",
        "        -webkit-text-fill-color: transparent;\n",
        "        background-clip: text;\n",
        "        font-size: 3.5rem;\n",
        "        font-weight: 800;\n",
        "        margin: 30px 0;\n",
        "        animation: gradient 3s ease infinite;\n",
        "        background-size: 200% auto;\n",
        "    }\n",
        "    @keyframes gradient {\n",
        "        0% { background-position: 0% 50%; }\n",
        "        50% { background-position: 100% 50%; }\n",
        "        100% { background-position: 0% 50%; }\n",
        "    }\n",
        "    .stats-card {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        padding: 25px;\n",
        "        border-radius: 20px;\n",
        "        text-align: center;\n",
        "        margin: 15px 0;\n",
        "        box-shadow: 0 10px 30px rgba(0,0,0,0.3);\n",
        "        animation: pulse 2s infinite;\n",
        "        position: relative;\n",
        "        overflow: hidden;\n",
        "    }\n",
        "    .stats-card::before {\n",
        "        content: '';\n",
        "        position: absolute;\n",
        "        top: -50%;\n",
        "        left: -50%;\n",
        "        width: 200%;\n",
        "        height: 200%;\n",
        "        background: linear-gradient(45deg, transparent, rgba(255,255,255,0.1), transparent);\n",
        "        transform: rotate(45deg);\n",
        "        animation: shine 3s infinite;\n",
        "    }\n",
        "    @keyframes shine {\n",
        "        0% { transform: translateX(-100%) translateY(-100%) rotate(45deg); }\n",
        "        100% { transform: translateX(100%) translateY(100%) rotate(45deg); }\n",
        "    }\n",
        "    @keyframes pulse {\n",
        "        0% { transform: scale(1); }\n",
        "        50% { transform: scale(1.02); }\n",
        "        100% { transform: scale(1); }\n",
        "    }\n",
        "    .model-info {\n",
        "        background: rgba(255,255,255,0.1);\n",
        "        backdrop-filter: blur(10px);\n",
        "        padding: 20px;\n",
        "        border-radius: 15px;\n",
        "        border: 1px solid rgba(255,255,255,0.2);\n",
        "        margin: 15px 0;\n",
        "        color: white;\n",
        "        transition: all 0.3s ease;\n",
        "    }\n",
        "    .model-info:hover {\n",
        "        background: rgba(255,255,255,0.15);\n",
        "        transform: translateY(-2px);\n",
        "        box-shadow: 0 5px 20px rgba(0,0,0,0.2);\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    with gr.Blocks(title=\"üé® Enhanced AI Image Studio\", theme=gr.themes.Soft(\n",
        "        primary_hue=\"purple\",\n",
        "        secondary_hue=\"blue\",\n",
        "        neutral_hue=\"gray\",\n",
        "        font=gr.themes.GoogleFont(\"Inter\")\n",
        "    ), css=css) as interface:\n",
        "\n",
        "        # Header with animation\n",
        "        gr.HTML(\"\"\"\n",
        "            <div class=\"title-header\">\n",
        "                üé® Enhanced AI Image Studio\n",
        "            </div>\n",
        "            <div style=\"text-align: center; color: #a0a0a0; font-size: 1.3em; margin-bottom: 40px;\">\n",
        "                Professional Stable Diffusion Interface with Advanced Features\n",
        "            </div>\n",
        "        \"\"\")\n",
        "\n",
        "        # Main tabs\n",
        "        with gr.Tabs() as tabs:\n",
        "            # Generation Tab\n",
        "            with gr.Tab(\"üé® Image Generation\", id=0):\n",
        "                # Statistics row\n",
        "                with gr.Row():\n",
        "                    stats_display = gr.HTML()\n",
        "\n",
        "                with gr.Row():\n",
        "                    # Left column - Advanced Controls\n",
        "                    with gr.Column(scale=1):\n",
        "                        with gr.Group():\n",
        "                            gr.Markdown(\"### ü§ñ Model Configuration\")\n",
        "\n",
        "                            model_selector = gr.Dropdown(\n",
        "                                choices=list(CONFIG[\"models\"].keys()),\n",
        "                                value=\"SD 1.5 Fast\",\n",
        "                                label=\"AI Model\",\n",
        "                                info=\"Select your preferred model\"\n",
        "                            )\n",
        "\n",
        "                            model_info = gr.HTML()\n",
        "\n",
        "                            scheduler_selector = gr.Dropdown(\n",
        "                                choices=CONFIG[\"schedulers\"],\n",
        "                                value=\"DPM Solver++\",\n",
        "                                label=\"Scheduler\",\n",
        "                                info=\"Sampling algorithm\"\n",
        "                            )\n",
        "\n",
        "                            with gr.Row():\n",
        "                                load_model_btn = gr.Button(\n",
        "                                    \"üì• Load Model\",\n",
        "                                    variant=\"primary\",\n",
        "                                    size=\"sm\"\n",
        "                                )\n",
        "\n",
        "                                optimal_settings_btn = gr.Button(\n",
        "                                    \"‚ö° Optimal Settings\",\n",
        "                                    variant=\"secondary\",\n",
        "                                    size=\"sm\"\n",
        "                                )\n",
        "\n",
        "                            model_status = gr.Textbox(\n",
        "                                label=\"Status\",\n",
        "                                value=\"‚ùå No model loaded\",\n",
        "                                interactive=False,\n",
        "                                max_lines=1\n",
        "                            )\n",
        "\n",
        "                        with gr.Group():\n",
        "                            gr.Markdown(\"### ‚úçÔ∏è Prompt Engineering\")\n",
        "\n",
        "                            # Preset management\n",
        "                            with gr.Row():\n",
        "                                preset_dropdown = gr.Dropdown(\n",
        "                                    choices=list(generator.presets.keys()),\n",
        "                                    label=\"Load Preset\",\n",
        "                                    scale=3\n",
        "                                )\n",
        "                                load_preset_btn = gr.Button(\"üìÇ\", scale=1)\n",
        "\n",
        "                            prompt = gr.Textbox(\n",
        "                                label=\"Prompt\",\n",
        "                                placeholder=\"Describe your image in detail...\",\n",
        "                                lines=4\n",
        "                            )\n",
        "\n",
        "                            negative_prompt = gr.Textbox(\n",
        "                                label=\"Negative Prompt\",\n",
        "                                placeholder=\"What to avoid...\",\n",
        "                                lines=2,\n",
        "                                value=\"blurry, low quality, distorted, ugly, bad anatomy\"\n",
        "                            )\n",
        "\n",
        "                            with gr.Row():\n",
        "                                style_preset = gr.Dropdown(\n",
        "                                    choices=[\"None\"] + list(CONFIG[\"style_presets\"].keys()),\n",
        "                                    value=\"None\",\n",
        "                                    label=\"Style Preset\",\n",
        "                                    scale=3\n",
        "                                )\n",
        "\n",
        "                                enhance_prompt_btn = gr.Button(\"‚ú®\", scale=1)\n",
        "\n",
        "                        with gr.Group():\n",
        "                            gr.Markdown(\"### ‚öôÔ∏è Generation Parameters\")\n",
        "\n",
        "                            size_selector = gr.Dropdown(\n",
        "                                label=\"Image Size\",\n",
        "                                choices=generator.get_available_sizes(\"SD 1.5 Fast\"),\n",
        "                                value=\"512x512 (Square)\"\n",
        "                            )\n",
        "\n",
        "                            with gr.Row():\n",
        "                                cfg_scale = gr.Slider(\n",
        "                                    minimum=1.0,\n",
        "                                    maximum=20.0,\n",
        "                                    value=7.5,\n",
        "                                    step=0.5,\n",
        "                                    label=\"CFG Scale\",\n",
        "                                    info=\"Prompt adherence\"\n",
        "                                )\n",
        "\n",
        "                                steps = gr.Slider(\n",
        "                                    minimum=10,\n",
        "                                    maximum=150,\n",
        "                                    value=30,\n",
        "                                    step=5,\n",
        "                                    label=\"Steps\",\n",
        "                                    info=\"Quality vs Speed\"\n",
        "                                )\n",
        "\n",
        "                            with gr.Row():\n",
        "                                seed = gr.Number(\n",
        "                                    label=\"Seed\",\n",
        "                                    value=-1,\n",
        "                                    precision=0,\n",
        "                                    info=\"-1 for random\"\n",
        "                                )\n",
        "\n",
        "                                batch_size = gr.Slider(\n",
        "                                    minimum=1,\n",
        "                                    maximum=8,\n",
        "                                    value=1,\n",
        "                                    step=1,\n",
        "                                    label=\"Batch Size\"\n",
        "                                )\n",
        "\n",
        "                        with gr.Group():\n",
        "                            gr.Markdown(\"### üé® Post-Processing\")\n",
        "\n",
        "                            with gr.Row():\n",
        "                                brightness = gr.Slider(\n",
        "                                    minimum=0.5,\n",
        "                                    maximum=2.0,\n",
        "                                    value=1.0,\n",
        "                                    step=0.1,\n",
        "                                    label=\"Brightness\"\n",
        "                                )\n",
        "\n",
        "                                contrast = gr.Slider(\n",
        "                                    minimum=0.5,\n",
        "                                    maximum=2.0,\n",
        "                                    value=1.0,\n",
        "                                    step=0.1,\n",
        "                                    label=\"Contrast\"\n",
        "                                )\n",
        "\n",
        "                            with gr.Row():\n",
        "                                saturation = gr.Slider(\n",
        "                                    minimum=0.0,\n",
        "                                    maximum=2.0,\n",
        "                                    value=1.0,\n",
        "                                    step=0.1,\n",
        "                                    label=\"Saturation\"\n",
        "                                )\n",
        "\n",
        "                                sharpness = gr.Slider(\n",
        "                                    minimum=0.0,\n",
        "                                    maximum=2.0,\n",
        "                                    value=1.0,\n",
        "                                    step=0.1,\n",
        "                                    label=\"Sharpness\"\n",
        "                                )\n",
        "\n",
        "                        # Action buttons\n",
        "                        with gr.Row():\n",
        "                            generate_btn = gr.Button(\n",
        "                                \"üöÄ Generate\",\n",
        "                                variant=\"primary\",\n",
        "                                size=\"lg\"\n",
        "                            )\n",
        "\n",
        "                            stop_btn = gr.Button(\n",
        "                                \"‚èπÔ∏è Stop\",\n",
        "                                variant=\"stop\",\n",
        "                                size=\"lg\"\n",
        "                            )\n",
        "\n",
        "                        with gr.Row():\n",
        "                            save_preset_btn = gr.Button(\"üíæ Save Preset\", size=\"sm\")\n",
        "                            preset_name_input = gr.Textbox(\n",
        "                                placeholder=\"Preset name...\",\n",
        "                                scale=2,\n",
        "                                visible=False\n",
        "                            )\n",
        "                            random_prompt_btn = gr.Button(\"üé≤ Random Prompt\", size=\"sm\")\n",
        "                            clear_btn = gr.Button(\"üóëÔ∏è Clear All\", size=\"sm\")\n",
        "\n",
        "                    # Right column - Results and Gallery\n",
        "                    with gr.Column(scale=1):\n",
        "                        with gr.Group():\n",
        "                            gr.Markdown(\"### üñºÔ∏è Generated Images\")\n",
        "\n",
        "                            gallery = gr.Gallery(\n",
        "                                label=\"Results\",\n",
        "                                show_label=False,\n",
        "                                elem_id=\"gallery\",\n",
        "                                columns=2,\n",
        "                                rows=2,\n",
        "                                object_fit=\"contain\",\n",
        "                                height=600\n",
        "                            )\n",
        "\n",
        "                            generation_status = gr.Textbox(\n",
        "                                label=\"Generation Status\",\n",
        "                                interactive=False,\n",
        "                                lines=3\n",
        "                            )\n",
        "\n",
        "                            with gr.Row():\n",
        "                                download_all_btn = gr.Button(\"üíæ Download All\", variant=\"secondary\")\n",
        "                                add_favorite_btn = gr.Button(\"‚≠ê Add to Favorites\", variant=\"secondary\")\n",
        "                                share_btn = gr.Button(\"üîó Share\", variant=\"secondary\")\n",
        "\n",
        "                        # Quick Examples\n",
        "                        with gr.Group():\n",
        "                            gr.Markdown(\"### üí° Quick Examples\")\n",
        "                            gr.Examples(\n",
        "                                examples=[\n",
        "                                    [\"A majestic dragon soaring over a mystical forest, fantasy art, highly detailed, 8k resolution, dramatic lighting\", \"Fantasy\"],\n",
        "                                    [\"Portrait of a cyberpunk hacker, neon lights, futuristic city background, blade runner style, rain, reflections\", \"Cyberpunk\"],\n",
        "                                    [\"Traditional Japanese garden with cherry blossoms, peaceful zen atmosphere, watercolor painting, soft colors\", \"Watercolor\"],\n",
        "                                    [\"Astronaut exploring alien planet with bioluminescent plants, sci-fi concept art, volumetric lighting\", \"Digital Art\"],\n",
        "                                    [\"Steampunk mechanical owl, brass gears, Victorian era, intricate details, golden hour lighting\", \"Photorealistic\"],\n",
        "                                    [\"Northern lights over snowy mountains, aurora borealis, night photography, long exposure, stars\", \"Photorealistic\"],\n",
        "                                    [\"Underwater coral reef, tropical fish, sun rays through water, vibrant colors, national geographic style\", \"Photorealistic\"],\n",
        "                                    [\"Medieval castle on a cliff, storm approaching, dramatic sky, fantasy landscape, epic scale\", \"Fantasy\"]\n",
        "                                ],\n",
        "                                inputs=[prompt, style_preset],\n",
        "                                label=\"\"\n",
        "                            )\n",
        "\n",
        "            # Analytics Tab\n",
        "            with gr.Tab(\"üìä Analytics & History\", id=1):\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        refresh_stats_btn = gr.Button(\"üîÑ Refresh Statistics\", variant=\"primary\")\n",
        "\n",
        "                        with gr.Row():\n",
        "                            model_usage_chart = gr.Plot(label=\"Model Usage\")\n",
        "                            style_pref_chart = gr.Plot(label=\"Style Preferences\")\n",
        "\n",
        "                        timeline_chart = gr.Plot(label=\"Generation Timeline\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"### üìú Generation History\")\n",
        "                        history_display = gr.Dataframe(\n",
        "                            headers=[\"ID\", \"Time\", \"Prompt\", \"Model\", \"Size\", \"Style\", \"Seed\"],\n",
        "                            label=\"Recent Generations\",\n",
        "                            interactive=False,\n",
        "                            wrap=True\n",
        "                        )\n",
        "\n",
        "                        with gr.Row():\n",
        "                            export_format = gr.Radio(\n",
        "                                choices=[\"json\", \"csv\"],\n",
        "                                value=\"json\",\n",
        "                                label=\"Export Format\"\n",
        "                            )\n",
        "                            export_btn = gr.Button(\"üì• Export History\", variant=\"secondary\")\n",
        "                            export_output = gr.File(label=\"Download Export\")\n",
        "\n",
        "            # Help Tab\n",
        "            with gr.Tab(\"üìö Help & Guide\", id=2):\n",
        "                gr.Markdown(\"\"\"\n",
        "                ## üéØ Enhanced AI Image Studio User Guide\n",
        "\n",
        "                ### üöÄ Quick Start\n",
        "                1. **Select a Model**: Choose from various models based on your needs\n",
        "                2. **Load the Model**: Click \"Load Model\" and wait for confirmation\n",
        "                3. **Craft Your Prompt**: Describe your desired image in detail\n",
        "                4. **Adjust Settings**: Fine-tune parameters for optimal results\n",
        "                5. **Generate**: Click \"Generate\" and watch the magic happen!\n",
        "\n",
        "                ### ü§ñ Model Comparison\n",
        "                | Model | Speed | Quality | Best For |\n",
        "                |-------|-------|---------|----------|\n",
        "                | SD 1.5 Fast | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Quick iterations |\n",
        "                | SD 1.5 Quality | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Balanced performance |\n",
        "                | SDXL Base | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Maximum quality |\n",
        "                | OpenJourney | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Artistic styles |\n",
        "                | DreamShaper | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Fantasy/Dreams |\n",
        "\n",
        "                ### üé® Style Presets\n",
        "                - **Photorealistic**: Ultra-realistic photos\n",
        "                - **Digital Art**: Modern digital illustrations\n",
        "                - **Anime**: Japanese animation style\n",
        "                - **Fantasy**: Magical and ethereal\n",
        "                - **Cyberpunk**: Futuristic neon aesthetics\n",
        "                - **Oil Painting**: Traditional art style\n",
        "\n",
        "                ### ‚öôÔ∏è Parameter Guide\n",
        "                - **CFG Scale (1-20)**:\n",
        "                  - 1-5: Very creative, loose interpretation\n",
        "                  - 7-10: Balanced creativity and accuracy\n",
        "                  - 15-20: Strict prompt following\n",
        "\n",
        "                - **Steps (10-150)**:\n",
        "                  - 10-25: Fast, lower quality\n",
        "                  - 30-50: Good balance\n",
        "                  - 50+: Maximum quality, slower\n",
        "\n",
        "                - **Seed**: Use same seed to reproduce exact results\n",
        "\n",
        "                ### üí° Pro Tips\n",
        "                1. **Prompt Engineering**:\n",
        "                   - Be specific and descriptive\n",
        "                   - Include style keywords: \"8k, highly detailed, artstation\"\n",
        "                   - Use negative prompts to avoid unwanted elements\n",
        "\n",
        "                2. **Performance Optimization**:\n",
        "                   - Start with fewer steps for testing\n",
        "                   - Use batch generation for variations\n",
        "                   - Enable memory optimizations for large images\n",
        "\n",
        "                3. **Quality Enhancement**:\n",
        "                   - Use post-processing sliders\n",
        "                   - Combine style presets with custom prompts\n",
        "                   - Generate at higher resolutions for details\n",
        "\n",
        "                ### üîß Troubleshooting\n",
        "                - **Out of Memory**: Enable CPU offload, reduce batch size\n",
        "                - **Slow Generation**: Lower steps, use SD 1.5 instead of SDXL\n",
        "                - **Poor Quality**: Increase steps, adjust CFG scale\n",
        "                - **Model Won't Load**: Clear cache and try again\n",
        "                \"\"\")\n",
        "\n",
        "        # Helper functions\n",
        "        def update_stats():\n",
        "            stats = generator.get_generation_stats()\n",
        "            progress_percent = (stats['total'] / stats['limit']) * 100\n",
        "\n",
        "            return f\"\"\"\n",
        "            <div class=\"stats-card\">\n",
        "                <h3>üìä Generation Progress</h3>\n",
        "                <div style=\"background: rgba(255,255,255,0.2); border-radius: 10px; padding: 5px; margin: 10px 0;\">\n",
        "                    <div style=\"background: linear-gradient(90deg, #4ecdc4 0%, #45b7d1 {progress_percent}%, transparent {progress_percent}%);\n",
        "                                height: 20px; border-radius: 10px; transition: all 0.5s ease;\"></div>\n",
        "                </div>\n",
        "                <p style=\"font-size: 1.2em; margin: 10px 0;\">\n",
        "                    <strong>{stats['total']}</strong> / {stats['limit']} images generated\n",
        "                </p>\n",
        "                <p style=\"font-size: 1.1em; opacity: 0.9;\">\n",
        "                    <strong>{stats['remaining']}</strong> generations remaining\n",
        "                </p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        def update_model_info(model_name):\n",
        "            info = CONFIG[\"models\"][model_name]\n",
        "            optimal = info[\"optimal_settings\"]\n",
        "            return f\"\"\"\n",
        "            <div class=\"model-info\">\n",
        "                <h4>ü§ñ {model_name}</h4>\n",
        "                <p>{info['description']}</p>\n",
        "                <p><strong>Type:</strong> {info['type'].upper()}</p>\n",
        "                <p><strong>Optimal Settings:</strong> {optimal['steps']} steps, {optimal['cfg']} CFG</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        def apply_optimal_settings(model_name):\n",
        "            if model_name in CONFIG[\"models\"]:\n",
        "                optimal = CONFIG[\"models\"][model_name][\"optimal_settings\"]\n",
        "                return optimal[\"cfg\"], optimal[\"steps\"]\n",
        "            return 7.5, 30\n",
        "\n",
        "        def update_size_options(model_name):\n",
        "            available_sizes = generator.get_available_sizes(model_name)\n",
        "            return gr.Dropdown(\n",
        "                choices=available_sizes,\n",
        "                value=available_sizes[0] if available_sizes else \"512x512 (Square)\"\n",
        "            )\n",
        "\n",
        "        def enhance_prompt(prompt, style):\n",
        "            \"\"\"Add quality enhancing keywords to prompt\"\"\"\n",
        "            quality_keywords = \"masterpiece, best quality, highly detailed, sharp focus, professional\"\n",
        "            if style != \"None\":\n",
        "                return f\"{prompt}, {quality_keywords}\"\n",
        "            return f\"{prompt}, {quality_keywords}, 8k uhd, dslr, high quality\"\n",
        "\n",
        "        def generate_random_prompt():\n",
        "            \"\"\"Generate a random creative prompt\"\"\"\n",
        "            subjects = [\"dragon\", \"castle\", \"forest\", \"warrior\", \"spaceship\", \"robot\", \"mermaid\", \"phoenix\",\n",
        "                       \"wizard\", \"fairy\", \"unicorn\", \"samurai\", \"knight\", \"witch\", \"angel\", \"demon\"]\n",
        "            settings = [\"mystical\", \"futuristic\", \"ancient\", \"underwater\", \"celestial\", \"steampunk\",\n",
        "                       \"magical\", \"cyberpunk\", \"ethereal\", \"apocalyptic\", \"frozen\", \"volcanic\"]\n",
        "            styles = [\"fantasy art\", \"concept art\", \"digital painting\", \"photorealistic\", \"oil painting\",\n",
        "                     \"watercolor\", \"anime style\", \"3d render\", \"comic book style\", \"impressionist\"]\n",
        "            moods = [\"epic\", \"serene\", \"dramatic\", \"mysterious\", \"peaceful\", \"intense\", \"dreamy\", \"dark\"]\n",
        "\n",
        "            subject = random.choice(subjects)\n",
        "            setting = random.choice(settings)\n",
        "            style = random.choice(styles)\n",
        "            mood = random.choice(moods)\n",
        "\n",
        "            prompts = [\n",
        "                f\"A {mood} {setting} {subject}, {style}, highly detailed, 8k\",\n",
        "                f\"{subject} in a {setting} environment, {mood} atmosphere, {style}, masterpiece\",\n",
        "                f\"Epic {subject}, {setting} atmosphere, {style}, award winning, {mood} lighting\",\n",
        "                f\"{mood} portrait of a {subject}, {setting} background, {style}, professional\",\n",
        "                f\"{setting} landscape with {subject}, {mood} mood, {style}, stunning composition\"\n",
        "            ]\n",
        "\n",
        "            return random.choice(prompts)\n",
        "\n",
        "        def refresh_history():\n",
        "            if not generator.history:\n",
        "                return []\n",
        "\n",
        "            # Get last 100 generations\n",
        "            recent = generator.history[-100:]\n",
        "            history_data = []\n",
        "            for item in recent:\n",
        "                history_data.append([\n",
        "                    item.get(\"id\", \"\"),\n",
        "                    item.get(\"timestamp\", \"\")[:19],\n",
        "                    item.get(\"prompt\", \"\")[:50] + \"...\" if len(item.get(\"prompt\", \"\")) > 50 else item.get(\"prompt\", \"\"),\n",
        "                    item.get(\"model\", \"\"),\n",
        "                    item.get(\"size\", \"\"),\n",
        "                    item.get(\"style_preset\", \"None\"),\n",
        "                    item.get(\"seed\", \"\")\n",
        "                ])\n",
        "            return history_data[::-1]  # Reverse to show newest first\n",
        "\n",
        "        def export_history_handler(format):\n",
        "            content = generator.export_history(format)\n",
        "            filename = f\"generation_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{format}\"\n",
        "\n",
        "            with open(filename, 'w', encoding='utf-8') as f:\n",
        "                f.write(content)\n",
        "\n",
        "            return filename\n",
        "\n",
        "        # Connect all event handlers\n",
        "        model_selector.change(\n",
        "            fn=update_model_info,\n",
        "            inputs=[model_selector],\n",
        "            outputs=[model_info]\n",
        "        )\n",
        "\n",
        "        model_selector.change(\n",
        "            fn=update_size_options,\n",
        "            inputs=[model_selector],\n",
        "            outputs=[size_selector]\n",
        "        )\n",
        "\n",
        "        load_model_btn.click(\n",
        "            fn=generator.load_model,\n",
        "            inputs=[model_selector, scheduler_selector],\n",
        "            outputs=[model_status]\n",
        "        )\n",
        "\n",
        "        optimal_settings_btn.click(\n",
        "            fn=apply_optimal_settings,\n",
        "            inputs=[model_selector],\n",
        "            outputs=[cfg_scale, steps]\n",
        "        )\n",
        "\n",
        "        generate_btn.click(\n",
        "            fn=generator.generate_batch,\n",
        "            inputs=[prompt, negative_prompt, model_selector, size_selector,\n",
        "                   cfg_scale, steps, seed, batch_size, style_preset,\n",
        "                   brightness, contrast, saturation, sharpness],\n",
        "            outputs=[gallery, generation_status]\n",
        "        ).then(\n",
        "            fn=update_stats,\n",
        "            outputs=[stats_display]\n",
        "        ).then(\n",
        "            fn=refresh_history,\n",
        "            outputs=[history_display]\n",
        "        )\n",
        "\n",
        "        enhance_prompt_btn.click(\n",
        "            fn=enhance_prompt,\n",
        "            inputs=[prompt, style_preset],\n",
        "            outputs=[prompt]\n",
        "        )\n",
        "\n",
        "        random_prompt_btn.click(\n",
        "            fn=generate_random_prompt,\n",
        "            outputs=[prompt]\n",
        "        )\n",
        "\n",
        "        clear_btn.click(\n",
        "            fn=lambda: (\"\", \"\", -1, 1.0, 1.0, 1.0, 1.0),\n",
        "            outputs=[prompt, negative_prompt, seed, brightness, contrast, saturation, sharpness]\n",
        "        )\n",
        "\n",
        "        refresh_stats_btn.click(\n",
        "            fn=generator.get_statistics,\n",
        "            outputs=[model_usage_chart, timeline_chart, style_pref_chart]\n",
        "        )\n",
        "\n",
        "        export_btn.click(\n",
        "            fn=export_history_handler,\n",
        "            inputs=[export_format],\n",
        "            outputs=[export_output]\n",
        "        )\n",
        "\n",
        "        # Initialize interface\n",
        "        interface.load(\n",
        "            fn=update_stats,\n",
        "            outputs=[stats_display]\n",
        "        )\n",
        "\n",
        "        interface.load(\n",
        "            fn=update_model_info,\n",
        "            inputs=[gr.State(\"SD 1.5 Fast\")],\n",
        "            outputs=[model_info]\n",
        "        )\n",
        "\n",
        "        interface.load(\n",
        "            fn=refresh_history,\n",
        "            outputs=[history_display]\n",
        "        )\n",
        "\n",
        "    return interface\n",
        "\n",
        "def main():\n",
        "    \"\"\"Enhanced main application entry point\"\"\"\n",
        "    print(\"üé® Enhanced AI Image Studio\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"‚ú® Professional Stable Diffusion Interface\")\n",
        "    print(\"üöÄ Version 2.0 with Advanced Features\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # System check\n",
        "    print(f\"üì± Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "    print(f\"üî¢ Generation Limit: {CONFIG['max_generations']}\")\n",
        "    print(f\"üìä Current Count: {CONFIG['generation_count']}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create and launch enhanced interface\n",
        "    try:\n",
        "        interface = create_enhanced_interface()\n",
        "\n",
        "        # Launch with appropriate settings\n",
        "        launch_kwargs = {\n",
        "            \"share\": True,\n",
        "            \"show_error\": True,\n",
        "            \"quiet\": False,\n",
        "            \"favicon_path\": None\n",
        "        }\n",
        "\n",
        "        if not IN_COLAB:\n",
        "            launch_kwargs.update({\n",
        "                \"server_name\": \"0.0.0.0\",\n",
        "                \"server_port\": 7860\n",
        "            })\n",
        "\n",
        "        print(\"üåê Launching Enhanced AI Image Studio...\")\n",
        "        interface.launch(**launch_kwargs)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Launch error: {e}\")\n",
        "        print(\"üîÑ Attempting fallback launch...\")\n",
        "        interface = create_enhanced_interface()\n",
        "        interface.launch(share=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "ry-0BA5GwQEH",
        "outputId": "1c8f2228-3a5e-467f-a1af-1f4392fec81e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Running in Google Colab - Enhanced Version\n",
            "üé® Enhanced AI Image Studio\n",
            "============================================================\n",
            "‚ú® Professional Stable Diffusion Interface\n",
            "üöÄ Version 2.0 with Advanced Features\n",
            "============================================================\n",
            "üì± Device: CUDA\n",
            "üéÆ GPU: Tesla T4\n",
            "üíæ GPU Memory: 14.7 GB\n",
            "üî¢ Generation Limit: 1000\n",
            "üìä Current Count: 0\n",
            "============================================================\n",
            "üåê Launching Enhanced AI Image Studio...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://70b0253fbd3304dd90.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://70b0253fbd3304dd90.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}